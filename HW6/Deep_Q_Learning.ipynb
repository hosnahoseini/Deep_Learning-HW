{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_zBh5XkFS2x"
      },
      "source": [
        "# In the name of God\n",
        "### HW6\n",
        "### Deep Q-Learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le8_aVDDFwXN"
      },
      "source": [
        "**Name:** Hosna Oyarhoseini\n",
        "\n",
        "**Std. No.:** 402212503"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43stiMNMF00N"
      },
      "source": [
        "\n",
        "### Deep Q-Learning (DQN)\n",
        "\n",
        "Deep Q-Learning is a popular algorithm in reinforcement learning that combines the ideas of Q-learning, a traditional reinforcement learning method, with deep neural networks. The goal is to train an agent to make decisions by estimating the optimal action-value function Q, which represents the expected cumulative future rewards for taking a particular action in a given state.\n",
        "\n",
        "Key components of DQN:\n",
        "\n",
        "- **Experience Replay:** To break the temporal correlation in sequential data and improve sample efficiency, we use an experience replay buffer to store and sample past experiences.\n",
        "- **Target Networks:** The use of two separate networks, the main network and a target network, helps stabilize training by decoupling the update targets from the online network's constantly changing values.\n",
        "\n",
        "### The Lunar Lander Problem\n",
        "\n",
        "The task is to control a lunar lander and guide it to land safely on the moon's surface. The agent needs to learn a policy that takes into account the lunar lander's state (position, velocity, angle, angular velocity, etc.) and chooses appropriate actions (thrust left, thrust right, thrust up, or do nothing) to achieve a safe landing.\n",
        "\n",
        "### Overview\n",
        "\n",
        "- **Environment:** LunarLander-v2 from OpenAI Gym.\n",
        "- **Objective:** Train an agent to learn a policy for landing the lunar lander safely.\n",
        "- **Techniques:** Deep Q-Learning, Experience Replay, Target Networks.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. Follow the instructions and comments in the code cells to implement and understand each component.\n",
        "2. Replace the `#####TO DO#####` placeholders with your code.\n",
        "3. Experiment with hyperparameters and observe how they affect the training process.\n",
        "4. Run the notebook to train the agent and play the game with the trained model.\n",
        "5. Answer any provided questions or tasks to reinforce your understanding.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Make sure you have the following libraries installed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_SIKDiCCBfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "e9665c10-a7b5-41a7-ab02-8f49182d36d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-69.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DllO2OwTCjh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5bcdd2-8f08-40ac-dffe-9c88c114852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.1.1.post1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1.post1\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (4.1.1.post1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373074 sha256=68181e555d0271bf6253530e711ce95ee355c65698d7b5f4131cf1c392590c2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gym[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWLFFqKfGcip"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJG1tV3p-8EM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895491b3-8bd6-4412-ba64-d3d881eb2da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "\n",
        "env = gym.make('LunarLander-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k--sktuIFlO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_features, n_actions):\n",
        "        \"\"\"\n",
        "        Initialize the Deep Q-Network (DQN).\n",
        "\n",
        "        Parameters:\n",
        "        - in_features (int): Number of input features (dimension of the state).\n",
        "        - n_actions (int): Number of possible actions in the environment.\n",
        "        \"\"\"\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        # TODO: Implement the neural network architecture\n",
        "        # Use Linear layers with ReLU\n",
        "        # Number of hidden units in each layer:\n",
        "        # - Layer 1: 256 units\n",
        "        # - Layer 2: 128 units\n",
        "        # - Layer 3: 64 units\n",
        "        self.neuralnet = nn.Sequential(\n",
        "            nn.Linear(in_features,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,n_actions)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define the forward pass of the neural network.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Input tensor representing the state.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Output tensor representing Q-values for each action.\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass\n",
        "        return self.neuralnet(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "B6zGowe__ac8",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class ExperienceBuffer():\n",
        "    def __init__(self, capacity):\n",
        "        \"\"\"\n",
        "        Initialize the Experience Replay Buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - capacity (int): Maximum capacity of the buffer.\n",
        "        \"\"\"\n",
        "        self.exp_buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def append(self, exp):\n",
        "        \"\"\"\n",
        "        Append a new experience to the buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - exp (tuple): Tuple representing a single experience (state, action, reward, done, next_state).\n",
        "        \"\"\"\n",
        "        self.exp_buffer.append(exp)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the current size of the buffer.\n",
        "\n",
        "        Returns:\n",
        "        - int: Number of experiences currently stored in the buffer.\n",
        "        \"\"\"\n",
        "        return len(self.exp_buffer)\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Clear all experiences from the buffer.\"\"\"\n",
        "        self.exp_buffer.clear()\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"\n",
        "        TODO: Sample a batch of experiences from the buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - batch_size (int): Size of the batch to be sampled.\n",
        "\n",
        "        Returns:\n",
        "        - tuple: Batch of experiences (states, actions, rewards, dones, next_states).\n",
        "        \"\"\"\n",
        "        # TODO: Implement the sampling logic\n",
        "\n",
        "\n",
        "        # TODO: Convert to NumPy arrays with appropriate data types\n",
        "        indices = np.random.choice( range(len(self.exp_buffer)), batch_size )\n",
        "        states,actions,rewards,dones,next_states = zip(*[self.exp_buffer[i] for i in indices])\n",
        "        return np.array(states),np.array(actions),np.array(rewards, dtype=np.float32),np.array(dones,dtype=np.uint8),np.array(next_states)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G8ZC4Jbc_oo6",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self, env, buffer):\n",
        "        \"\"\"\n",
        "        Initialize the agent.\n",
        "\n",
        "        Parameters:\n",
        "        - env: The environment the agent interacts with.\n",
        "        - buffer: Experience replay buffer to store agent experiences.\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.buffer = buffer\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"\n",
        "        Reset the agent's state and total rewards to the initial state.\n",
        "        \"\"\"\n",
        "        self.state = env.reset()\n",
        "        self.total_rewards = 0.0\n",
        "\n",
        "    def step(self, net, eps, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        TODO: Implement the exploration-exploitation strategy (epsilon-greedy) here.\n",
        "\n",
        "        Take a step in the environment using the provided neural network.\n",
        "\n",
        "        Parameters:\n",
        "        - net: The neural network representing the agent's policy.\n",
        "        - eps (float): Epsilon value for epsilon-greedy exploration.\n",
        "        - device (str): Device for neural network computations.\n",
        "\n",
        "        Returns:\n",
        "        - done_reward: Total rewards obtained in the episode if it is finished, otherwise None.\n",
        "        \"\"\"\n",
        "        done_reward = None\n",
        "\n",
        "        # TODO: Implement exploration-exploitation strategy here\n",
        "\n",
        "        # TODO: Take the selected action for 4 time steps (adjustable)\n",
        "\n",
        "        # TODO: Append the experience to the buffer\n",
        "\n",
        "        if np.random.random() < eps:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_prev = torch.tensor(self.state).to(device)\n",
        "            action = int(torch.argmax(net(state_prev).to(device)))\n",
        "\n",
        "        state_prev = self.state\n",
        "        rewards = 0\n",
        "        done = False\n",
        "        for _ in range(4):\n",
        "            self.state,reward,done,info = env.step(action)\n",
        "            self.total_rewards+=reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        self.buffer.append((state_prev,action,reward,done,self.state))\n",
        "        if done:\n",
        "            done_reward = self.total_rewards\n",
        "            self._reset()\n",
        "        return done_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U5sWRHaU_fD7",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "GAMMA = 0.99  # Discount factor for future rewards\n",
        "EPSILON_START = 1.0  # Initial exploration probability (epsilon-greedy)\n",
        "EPSILON_FINAL = 0.01  # Final exploration probability (epsilon-greedy)\n",
        "EPSILON_DECAY_OBS = 10**5  # Number of observations for epsilon decay\n",
        "BATCH_SIZE = 32  # Size of the experience replay batch\n",
        "MEAN_GOAL_REWARD = 250  # Mean reward goal for solving the environment\n",
        "REPLAY_BUFFER_SIZE = 10000  # Maximum capacity of the experience replay buffer\n",
        "REPLAY_MIN_SIZE = 10000  # Minimum size of the experience replay buffer before training begins\n",
        "LEARNING_RATE = 1e-4  # Learning rate for the neural network optimizer\n",
        "SYNC_TARGET_OBS = 1000  # Number of observations before synchronizing target and online networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FItvw2-BD6gm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def cal_loss(batch, net, tgt_net, device='cpu'):\n",
        "    \"\"\"\n",
        "    TODO: Implement the loss calculation for Deep Q-Learning.\n",
        "\n",
        "    Calculate the loss for Deep Q-Learning.\n",
        "\n",
        "    Parameters:\n",
        "    - batch (tuple): Batch of experiences (states, actions, rewards, dones, next_states).\n",
        "    - net: The neural network representing the online Q-network.\n",
        "    - tgt_net: The neural network representing the target Q-network.\n",
        "    - device (str): Device for neural network computations (default is \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Loss value calculated using Mean Squared Error (MSE) loss.\n",
        "    \"\"\"\n",
        "\n",
        "    states, actions, rewards, dones, next_states = batch\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "    dones_v = torch.BoolTensor(dones).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "\n",
        "    # TODO: Calculate Q-values for the current states and selected actions\n",
        "\n",
        "    # TODO: Calculate the maximum Q-value for the next states using the target network\n",
        "\n",
        "    # TODO: Zero out Q-values for terminal states\n",
        "\n",
        "    # TODO: Detach Q-values for the next states to avoid gradient flow\n",
        "\n",
        "    # TODO: Calculate the expected return for the current states\n",
        "\n",
        "    # TODO: Implement the Mean Squared Error (MSE) loss calculation\n",
        "\n",
        "    Q_val = net(states_v).gather(1,actions_v.unsqueeze(-1)).squeeze(-1) #select q value corresponding each action\n",
        "    Q_val_next = tgt_net(next_states_v).max(1)[0] #give maximum value for each sample\n",
        "    Q_val_next[dones_v] = 0.0 #making q value for done to zero\n",
        "    Q_val_next = Q_val_next.detach() #detach from current graph\n",
        "\n",
        "    expected_return = rewards_v + GAMMA * Q_val_next #what should be\n",
        "    loss = nn.MSELoss()(Q_val,expected_return)\n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZadHztDQVs0"
      },
      "source": [
        "# Learning Curves\n",
        " Plot learning curves showing key metrics (e.g., total rewards, loss) over the course of training. Analyze the trends and identify key points in the learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdXuc3WBAjbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de793baa-4c83-4f50-8f71-5378862b6463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAME : 36547, TIME ECLAPSED : 0.09556722640991211, EPSILON : 0.63453, MEAN_REWARD : -116.83931582706424\n",
            "Reward -118.9093096213422 -> -116.83931582706424 Model Saved\n",
            "GAME : 44293, TIME ECLAPSED : 0.14898228645324707, EPSILON : 0.55707, MEAN_REWARD : -105.98237177628386\n",
            "Reward -108.44389305700075 -> -105.98237177628386 Model Saved\n",
            "GAME : 44948, TIME ECLAPSED : 0.3033437728881836, EPSILON : 0.55052, MEAN_REWARD : -97.32740616178982\n",
            "Reward -97.40940087866642 -> -97.32740616178982 Model Saved\n",
            "GAME : 74904, TIME ECLAPSED : 0.8536584377288818, EPSILON : 0.25095999999999996, MEAN_REWARD : -86.17904583166464\n",
            "Reward -86.23238984812107 -> -86.17904583166464 Model Saved\n",
            "GAME : 75627, TIME ECLAPSED : 0.46413254737854004, EPSILON : 0.24373, MEAN_REWARD : -70.92806585399686\n",
            "Reward -74.56118920582112 -> -70.92806585399686 Model Saved\n",
            "GAME : 76380, TIME ECLAPSED : 0.4919860363006592, EPSILON : 0.23619999999999997, MEAN_REWARD : -58.22508600586745\n",
            "Reward -61.21338682625072 -> -58.22508600586745 Model Saved\n",
            "GAME : 76687, TIME ECLAPSED : 0.543421745300293, EPSILON : 0.23312999999999995, MEAN_REWARD : -46.29057390368677\n",
            "Reward -49.30952544611256 -> -46.29057390368677 Model Saved\n",
            "GAME : 77539, TIME ECLAPSED : 0.7837796211242676, EPSILON : 0.22460999999999998, MEAN_REWARD : -35.4910222846651\n",
            "Reward -39.277821555892416 -> -35.4910222846651 Model Saved\n",
            "GAME : 78287, TIME ECLAPSED : 0.279799222946167, EPSILON : 0.21713000000000005, MEAN_REWARD : -27.437354485327216\n",
            "Reward -27.772713334579553 -> -27.437354485327216 Model Saved\n",
            "GAME : 78759, TIME ECLAPSED : 0.7129168510437012, EPSILON : 0.21241, MEAN_REWARD : -14.16225570654146\n",
            "Reward -17.488445745642963 -> -14.16225570654146 Model Saved\n",
            "GAME : 79256, TIME ECLAPSED : 0.45623326301574707, EPSILON : 0.20743999999999996, MEAN_REWARD : -0.15479285258881903\n",
            "Reward -3.8780006388538686 -> -0.15479285258881903 Model Saved\n",
            "GAME : 79742, TIME ECLAPSED : 0.5300266742706299, EPSILON : 0.20257999999999998, MEAN_REWARD : 11.720497086963094\n",
            "Reward 8.404351512936985 -> 11.720497086963094 Model Saved\n",
            "GAME : 80157, TIME ECLAPSED : 0.8088700771331787, EPSILON : 0.19843, MEAN_REWARD : 22.551622632450158\n",
            "Reward 19.356188863574676 -> 22.551622632450158 Model Saved\n",
            "GAME : 80478, TIME ECLAPSED : 0.5287206172943115, EPSILON : 0.19521999999999995, MEAN_REWARD : 34.34676647291808\n",
            "Reward 30.771052274663205 -> 34.34676647291808 Model Saved\n",
            "GAME : 81007, TIME ECLAPSED : 0.6166477203369141, EPSILON : 0.18993000000000004, MEAN_REWARD : 44.36280415978348\n",
            "Reward 41.18846211039315 -> 44.36280415978348 Model Saved\n",
            "GAME : 81449, TIME ECLAPSED : 1.0250263214111328, EPSILON : 0.18550999999999995, MEAN_REWARD : 58.31307270744572\n",
            "Reward 55.5213569442576 -> 58.31307270744572 Model Saved\n",
            "GAME : 81841, TIME ECLAPSED : 0.6870212554931641, EPSILON : 0.18159000000000003, MEAN_REWARD : 74.90523240775588\n",
            "Reward 68.27497025188327 -> 74.90523240775588 Model Saved\n",
            "GAME : 82160, TIME ECLAPSED : 0.60030198097229, EPSILON : 0.1784, MEAN_REWARD : 83.01303842717988\n",
            "Reward 79.84921488990638 -> 83.01303842717988 Model Saved\n",
            "GAME : 82541, TIME ECLAPSED : 0.5466821193695068, EPSILON : 0.17459000000000002, MEAN_REWARD : 93.58601836150879\n",
            "Reward 91.19425972359808 -> 93.58601836150879 Model Saved\n",
            "GAME : 82840, TIME ECLAPSED : 0.5191144943237305, EPSILON : 0.17159999999999997, MEAN_REWARD : 109.62834960639877\n",
            "Reward 105.90203246516253 -> 109.62834960639877 Model Saved\n",
            "GAME : 83457, TIME ECLAPSED : 2.1350438594818115, EPSILON : 0.16542999999999997, MEAN_REWARD : 118.5461793845679\n",
            "Reward 117.55962708526314 -> 118.5461793845679 Model Saved\n",
            "GAME : 83917, TIME ECLAPSED : 0.5091629028320312, EPSILON : 0.16083000000000003, MEAN_REWARD : 132.41751814621048\n",
            "Reward 128.63039761890658 -> 132.41751814621048 Model Saved\n",
            "GAME : 84305, TIME ECLAPSED : 0.6391904354095459, EPSILON : 0.15695000000000003, MEAN_REWARD : 144.46124141192388\n",
            "Reward 138.7667445002343 -> 144.46124141192388 Model Saved\n",
            "GAME : 85167, TIME ECLAPSED : 0.4253227710723877, EPSILON : 0.14832999999999996, MEAN_REWARD : 151.6283325769937\n",
            "Reward 151.61332115143986 -> 151.6283325769937 Model Saved\n",
            "GAME : 87369, TIME ECLAPSED : 0.6143348217010498, EPSILON : 0.12631000000000003, MEAN_REWARD : 163.87993335061327\n",
            "Reward 163.6745312110064 -> 163.87993335061327 Model Saved\n",
            "GAME : 88476, TIME ECLAPSED : 0.23842167854309082, EPSILON : 0.11524000000000001, MEAN_REWARD : 176.011825622728\n",
            "Reward 175.39098668196507 -> 176.011825622728 Model Saved\n",
            "GAME : 91563, TIME ECLAPSED : 0.4212071895599365, EPSILON : 0.08436999999999995, MEAN_REWARD : 185.7383575564463\n",
            "Reward 185.4822004414226 -> 185.7383575564463 Model Saved\n",
            "GAME : 93479, TIME ECLAPSED : 0.3281998634338379, EPSILON : 0.06520999999999999, MEAN_REWARD : 196.4026005362385\n",
            "Reward 196.1948250313743 -> 196.4026005362385 Model Saved\n",
            "GAME : 94393, TIME ECLAPSED : 0.3726811408996582, EPSILON : 0.05606999999999995, MEAN_REWARD : 208.7965296691816\n",
            "Reward 208.4569350524368 -> 208.7965296691816 Model Saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAME : 104102, TIME ECLAPSED : 0.30881643295288086, EPSILON : 0.01, MEAN_REWARD : 219.67468869857748\n",
            "Reward 219.36305160573414 -> 219.67468869857748 Model Saved\n",
            "GAME : 113652, TIME ECLAPSED : 0.17425942420959473, EPSILON : 0.01, MEAN_REWARD : 230.1897552382733\n",
            "Reward 229.39953119770996 -> 230.1897552382733 Model Saved\n",
            "GAME : 155785, TIME ECLAPSED : 0.17681503295898438, EPSILON : 0.01, MEAN_REWARD : 241.12098535957853\n",
            "Reward 241.0746593590654 -> 241.12098535957853 Model Saved\n",
            "SOLVED in 163613 obs\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net = DQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_BUFFER_SIZE)\n",
        "\n",
        "agent = Agent(env, buffer)\n",
        "\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Lists to track total rewards and losses over training\n",
        "total_rewards = []\n",
        "losses = []\n",
        "\n",
        "# Initialize time variables for tracking training time\n",
        "ts = time.time()\n",
        "best_mean_reward = None\n",
        "obs_id = 0\n",
        "\n",
        "while True:\n",
        "    obs_id += 1\n",
        "\n",
        "    # Update exploration rate based on epsilon decay schedule\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - obs_id/EPSILON_DECAY_OBS)\n",
        "\n",
        "    # Agent takes a step in the environment, receives a reward\n",
        "    reward = agent.step(net, epsilon, device=device)\n",
        "\n",
        "    if reward is not None:\n",
        "        # Store total rewards and update game time\n",
        "        total_rewards.append(reward)\n",
        "        game_time = time.time() - ts\n",
        "        ts = time.time()\n",
        "        mean_reward = np.mean(total_rewards[-100:])\n",
        "\n",
        "\n",
        "        if best_mean_reward is None or best_mean_reward < mean_reward:\n",
        "            torch.save(net.state_dict(), './lunar_lander-best.dat')\n",
        "\n",
        "            if best_mean_reward is None:\n",
        "                last = mean_reward\n",
        "                best_mean_reward = mean_reward\n",
        "\n",
        "            if best_mean_reward is not None and best_mean_reward - last > 10:\n",
        "                last = best_mean_reward\n",
        "                print(\"GAME : {}, TIME ECLAPSED : {}, EPSILON : {}, MEAN_REWARD : {}\"\n",
        "                      .format(obs_id, game_time, epsilon, mean_reward))\n",
        "                print(\"Reward {} -> {} Model Saved\".format(best_mean_reward, mean_reward))\n",
        "\n",
        "            best_mean_reward = mean_reward\n",
        "\n",
        "        if mean_reward > MEAN_GOAL_REWARD:\n",
        "            print(\"SOLVED in {} obs\".format(obs_id))\n",
        "            break\n",
        "\n",
        "    # Continue training if the replay buffer size is below the minimum required\n",
        "    if len(buffer) < REPLAY_MIN_SIZE:\n",
        "        continue\n",
        "\n",
        "    # Synchronize target network with the Q-network at regular intervals\n",
        "    if obs_id % SYNC_TARGET_OBS == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = cal_loss(batch,net,tgt_net,device= device)\n",
        "    losses.append(loss_t.item())\n",
        "\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # TODO: Plot learning curves every few episodes or steps\n",
        "    PLOT_INTERVAL = 100000\n",
        "    if obs_id % PLOT_INTERVAL == 0 and obs_id != 0:\n",
        "        plt.plot(losses, label='Loss')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss Over Episodes')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZygyvBOzLe"
      },
      "source": [
        "# Visual Comparison:\n",
        "\n",
        "write a function to render and display the environment before and after training. What visual differences do you observe in the agent's behavior? Discuss it. Also, Upload the Videos with your notebook. You can use the following library for rendering and saving videos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I couldn't show the videos on colab so I saved them as mp4 files and attach them."
      ],
      "metadata": {
        "id": "2-fJnpi9j4iM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_ClI7VqMHgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d505483-ea5b-4b02-d296-78ece7f7b844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### BEFORE TRAINING ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "<ipython-input-19-6a441adb7084>:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  obs = torch.FloatTensor([obs]).to(device)\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### AFTER TRAINING ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "\n",
        "# Helper function for rendering and saving a video\n",
        "def render_and_save_video(env, net, episodes=10, save_path=\"./render_video.mp4\", device=\"cpu\"):\n",
        "    images = []  # List to store frames\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # Render the current state\n",
        "            frame = env.render(mode='rgb_array')\n",
        "            images.append(frame)\n",
        "\n",
        "            # Convert observation to tensor and move to the specified device\n",
        "            obs = torch.FloatTensor([obs]).to(device)\n",
        "\n",
        "            # Choose the action using the trained network\n",
        "            with torch.no_grad():\n",
        "                action = net(obs).argmax(dim=1).item()\n",
        "\n",
        "            # Take a step in the environment\n",
        "            obs, _, done, _ = env.step(action)\n",
        "\n",
        "    # Save the frames as a video\n",
        "    imageio.mimsave(save_path, images)\n",
        "\n",
        "# Render and save a video before training\n",
        "print(\"### BEFORE TRAINING ###\")\n",
        "render_and_save_video(env, net, episodes=1, device=device, save_path='./before.mp4')\n",
        "\n",
        "# Render and save a video after training\n",
        "print(\"### AFTER TRAINING ###\")\n",
        "render_and_save_video(env, net, episodes=1, device=device, save_path='./after.mp4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsGQY4DQ9Z_"
      },
      "source": [
        "# Question:\n",
        "\n",
        "Exploration (Epsilon-Greedy):\n",
        "\n",
        "Discuss the significance of the exploration strategy, specifically the Epsilon-Greedy approach, in balancing exploration and exploitation during training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The exploration strategy, specifically the Epsilon-Greedy approach, plays a crucial role in reinforcement learning as it allows for a delicate balance between exploration and exploitation. In this type of learning, the main challenge is to find the best possible course of action within a given environment by actively engaging with it. This requires a careful consideration of both exploiting current knowledge for immediate gain and exploring uncharted territories in the hopes of discovering better strategies. To address this dilemma, the Epsilon-Greedy strategy offers a straightforward yet powerful solution. Here's how it works:\n",
        "\n",
        " **Exploitation (Greedy Action):** By choosing the most optimal course of action with a probability of $$(1 - \\epsilon)$$, the agent takes advantage of its existing knowledge. This is known as exploitation."
      ],
      "metadata": {
        "id": "owZb_bUScgy6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4B64BpccqgK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}